import os

from grammatical_evolution.model import _grammar


def test_grammar_parsing():
    """
    This test case checks if a grammar text string can be parsed correctly into a _Grammar object,
    which contains: terminals, non-terminals and rules.
    """
    # Create a _Grammar instance with a simple grammar text
    grammar_text = "<NT> ::= T | T<NT>"
    grammar = _grammar._Grammar(grammar_text=grammar_text, verbose=False)

    # Test that non-terminals and terminals are correctly parsed
    assert "<NT>" in grammar.non_terminals
    assert "T" in grammar.terminals

    # Test that rules are correctly parsed
    assert len(grammar.rules) == 1
    assert "<NT>" in grammar.rules
    assert len(grammar.rules["<NT>"]) == 2

    # Test that start rule is correctly set
    assert grammar.start_rule == ("<NT>", "NT")

    # Test another simple grammar
    another_grammar_text = "<S> ::= a<S>b | T"
    another_grammar = _grammar._Grammar(grammar_text=another_grammar_text, verbose=False)

    assert "<S>" in another_grammar.non_terminals
    assert "T" in another_grammar.terminals
    assert len(another_grammar.rules) == 1
    assert "<S>" in another_grammar.rules
    assert len(another_grammar.rules["<S>"]) == 2
    assert another_grammar.start_rule == ("<S>", "NT")


def test_generate_phenotype():
    """
    This test case now tries to perform a mapping from a genome to a phenotype using the rules available.
    """
    # Create a _Grammar instance with a simplified grammar text
    grammar_text = "<NT> ::= T | T<NT>"
    grammar = _grammar._Grammar(grammar_text=grammar_text, verbose=False)

    # Call the generate_phenotype function with a sample input genome
    phenotype, used_codons, used_symbols = grammar.generate_phenotype([1, 2, 3])

    # Test assertions
    assert isinstance(phenotype, str)
    assert isinstance(used_codons, int)
    assert isinstance(used_symbols, list)
    assert len(phenotype) > 0
    assert used_codons > 0
    assert len(used_symbols) > 0


def test_used_codons_pks():
    """
    This test now uses a more sophisticated grammar, which is actually used in the PKevo tool to generate 
    PKS for polyketides. Specifically, we are testing if the counting of how many genes from the genome
    are used for the mapping (= used codons) is correct. For that we use the minimal genome, which is able
    to produce a valid PKS without wrapping. Then we use a shortened version of that genome, which enforces
    the algorithm to use wrapping (= meaning that the mapping process is started once over from the beginning
    of the genome).
    """

    # Get the current directory where this script is located
    current_dir = os.path.dirname(os.path.abspath(__file__))

    # Construct the path to the grammar file
    grammar_file_path = os.path.join(current_dir, '..', 'grammatical_evolution', 'grammars', 'pytest_pks.bnf')
    grammar = _grammar._Grammar(grammar_file_path=grammar_file_path, verbose=False)


    # to get a valid minimal PKS without having to rely on wrapping, we need exactly 6 genes. 
    # Note: Some rules have the possibility to invoke themselves (leading to longer, more complex PKS), using only even numbers ensures those 
    # production choices are not selected
    min_complete_pks_genome = [16, 0, 0, 16, 0, 0]
    phenotype, used_codons, used_symbols = grammar.generate_phenotype(min_complete_pks_genome)
    
    assert phenotype == "AT(Methylmalonyl)-ACP--KS-AT(Ethylmalonyl)-ACP--TE(Claisen)"
    assert used_codons == len(min_complete_pks_genome)

    # Now we use just the first half of the previous genome. Without wrapping we should not be able to generate a valid phenotype
    partial_pks_genome = [16, 0, 0]
    phenotype2, used_codons2, used_symbols2 = grammar.generate_phenotype(partial_pks_genome, max_wraps=0)

    assert phenotype2 is None

    # However, when allowing for wrapping (which is the default setting, we should now get the exact same result as with the first genome
    phenotype3, used_codons3, used_symbols3 = grammar.generate_phenotype(partial_pks_genome, max_wraps=2)

    assert phenotype3 == "AT(Methylmalonyl)-ACP--KS-AT(Ethylmalonyl)-ACP--TE(Claisen)"
    assert used_codons3 == len(min_complete_pks_genome) # amount of used codons should be again equal to length of the minimal genome


def test_deconstruct_string():

    # Get the current directory where this script is located
    current_dir = os.path.dirname(os.path.abspath(__file__))

    # Construct the path to the grammar file
    grammar_file_path = os.path.join(current_dir, '..', 'grammatical_evolution', 'grammars', 'pytest_pks.bnf')
    grammar = _grammar._Grammar(grammar_file_path=grammar_file_path, verbose=False)

    # Random example PKS generated by PKevo
    expected_elements = ['AT', '2-Methylbutyryl', 'ACP', 'KS', 'AT', 'Ethylmalonyl', 'ACP', 'TE', 'Claisen']
    result_elements = grammar.deconstruct_string("AT(2-Methylbutyryl)-ACP--KS-AT(Ethylmalonyl)-ACP--TE(Claisen)")
    assert result_elements == expected_elements

    # 'real-life' engineered PKS, which should be able to produce triketide lactone
    expected_elements_2 = ['AT', 'Propionyl', 'ACP', 'KS', 'AT', 'Malonyl', 'KR', 'ACP', 'KS', 'AT', 'Malonyl', 'KR', 'ACP', 'TE', 'Macrolactonization']
    result_elements_2 = grammar.deconstruct_string("AT(Propionyl)-ACP--KS-AT(Malonyl)-KR-ACP--KS-AT(Malonyl)-KR-ACP--TE(Macrolactonization)")
    assert result_elements_2 == expected_elements_2

    # Geldanamycin PKS example
    geldanamycin_str = "AT(AHBA)-ACP--KS-AT(Methylmalonyl)-KR-DH-ER-ACP--KS-AT(Methoxymalonyl)-KR-DH-ER-ACP--KS-AT(Methylmalonyl)-KR-ACP--KS-AT(Methylmalonyl)-KR-DH-ACP--KS-AT(Methoxymalonyl)-KR-ACP--KS-AT(Malonyl)-KR-DH-ER-ACP--KS-AT(Methylmalonyl)-KR-DH-ACP--TE(Macrolactamization)"
    geldanamycin_expected_assembly = ['AT', 'AHBA', 'ACP', 'KS', 'AT', 'Methylmalonyl', 'KR', 'DH', 'ER', 'ACP', 'KS', 'AT', 'Methoxymalonyl', 'KR', 'DH', 'ER', 'ACP', 'KS', 'AT', 'Methylmalonyl', 'KR', 'ACP', 'KS', 'AT', 'Methylmalonyl', 'KR', 'DH', 'ACP', 'KS', 'AT', 'Methoxymalonyl', 'KR', 'ACP', 'KS', 'AT', 'Malonyl', 'KR', 'DH', 'ER', 'ACP', 'KS', 'AT', 'Methylmalonyl', 'KR', 'DH', 'ACP', 'TE', 'Macrolactamization']
    geldanamycin_assembly = grammar.deconstruct_string(geldanamycin_str)
    assert geldanamycin_expected_assembly == geldanamycin_assembly

    erythromycin_str = "AT(Propionyl)-ACP--KS-AT(Methylmalonyl)-KR-ACP--KS-AT(Methylmalonyl)-KR-ACP--KS-AT(Methylmalonyl)-ACP--KS-AT(Methylmalonyl)-KR-DH-ER-ACP--KS-AT(Methylmalonyl)-KR-ACP--KS-AT(Methylmalonyl)-KR-ACP--TE(Macrolactonization)"
    erythromycin_expected_assembly = ['AT', 'Propionyl', 'ACP', 'KS', 'AT', 'Methylmalonyl', 'KR', 'ACP', 'KS', 'AT', 'Methylmalonyl', 'KR', 'ACP', 'KS', 'AT', 'Methylmalonyl', 'ACP', 'KS', 'AT', 'Methylmalonyl', 'KR', 'DH', 'ER', 'ACP', 'KS', 'AT', 'Methylmalonyl', 'KR', 'ACP', 'KS', 'AT', 'Methylmalonyl', 'KR', 'ACP', 'TE', 'Macrolactonization']
    erythromycin_assembly = grammar.deconstruct_string(erythromycin_str)
    assert erythromycin_expected_assembly == erythromycin_assembly